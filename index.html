<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>Erik Miehling</title>
    <link rel="stylesheet" href="assets/styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
    <script>
      (function() {
        const theme = localStorage.getItem('theme-preference') || 
          (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light');
        document.documentElement.setAttribute('data-theme', theme);
      })();
    </script>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Erik Miehling</h1>

        <img src="assets/images/profile.jpeg" alt="Profile photo" class="profile-photo">

        <p class="sidebar-email">erik.miehling@ibm.com</p>

        <ul class="sidebar-links">
          <li>
            <a href="assets/miehling_resume.pdf">
              <i class="fa-regular fa-file fa-fw"></i>
              <span>Resume</span>
            </a>
          </li>
          <li>
            <a href="https://scholar.google.com/citations?user=mmd29pMAAAAJ&hl=en">
              <i class="fa-brands fa-google-scholar fa-fw"></i>
              <span>Google Scholar</span>
            </a>
          </li>
          <li>
            <a href="https://github.com/emiehling">
              <i class="fa-brands fa-github fa-fw"></i>
              <span>GitHub</span>
            </a>
          </li>
          <li>
            <a href="https://www.linkedin.com/in/erik-miehling/">
              <i class="fa-brands fa-linkedin fa-fw"></i>
              <span>LinkedIn</span>
            </a>
          </li>
          <li>
            <a href="https://x.com/erikmiehling">
              <i class="fa-brands fa-x-twitter fa-fw"></i>
              <span>X page</span>
            </a>
          </li>
        </ul>

        <footer>
          <div class="theme-toggle-wrapper">
            <span class="theme-toggle-icon sun"><i class="fa-solid fa-sun"></i></span>
            <button class="theme-toggle" aria-label="Toggle dark mode" aria-checked="false" role="switch"></button>
            <span class="theme-toggle-icon moon"><i class="fa-solid fa-moon"></i></span>
          </div>
          <p><small>Theme forked from <a href="https://github.com/orderedlist">orderedlist</a></small></p>
        </footer>
      </header>

      <div class="content-area">
        <article class="about-section">
          <h1>About</h1>

          <p>I am a research scientist at <a href="https://research.ibm.com">IBM Research</a> in the <a href="https://research.ibm.com/topics/trustworthy-ai">trustworthy AI</a> group. My primary research interests lie in the steerability of generative models, multi-agent coordination and alignment, and the dynamics of human-AI interaction.</p>

          <p>Prior to joining IBM Research I was a postdoctoral research associate in the <a href="https://csl.illinois.edu">Coordinated Science Lab</a> at the University of Illinois at Urbana–Champaign where I worked with <a href="http://tamerbasar.csl.illinois.edu">Tamer Başar</a> and <a href="https://aerospace.illinois.edu/directory/profile/langbort">Cedric Langbort</a> on problems in reinforcement learning, control, and games. I obtained my PhD in electrical engineering and computer science at the University of Michigan under <a href="https://teneketzis.engin.umich.edu">Demos Teneketzis</a>.</p>

          <h2>Model steerability and safety</h2>

          <p>I share the view that model steerability (i.e., controllability) is a more direct and sustainable target for AI safety than model alignment, in that it forces us to focus on questions of how corrigibility/oversight can be preserved as model capabilities grow. Understanding how steerable models are toward particular behaviors also informs which model capabilities should be constrained. See Kush Varshney's <a href="https://research.ibm.com/blog/map-measure-manage-gen-ai">interview</a> and Helen Toner's <a href="https://helentoner.substack.com/p/the-core-challenge-of-ai-alignment">post</a> for more on these ideas.</p>

          <p>To better understand model steerability generally, I've been leading the development of the <a href="https://ibm.github.io/AISteer360/">AI Steerability 360 toolkit</a>. The toolkit allows for the design of new steering methods, the analysis of how much a model can be controlled (or steered), and the (empirical) study of any unintended side effects that were introduced through steering.</p>

          <!-- <p>Check out our the technical report on the toolkit </p> -->

          <h2>Multi-agent systems</h2>

          <p>Another focus area of my research concerns multi-agent systems, specifically how we can effectively monitor if collectives of LLM-based agents are behaving as intended, and what we can do to intervene if their goals start to drift. Given that agentic AI systems are being deployed in environments that interface with humans, the tools used to understand these systems must draw upon theory from domains beyond engineering. Check out <a href="https://fast-workshop.github.io">our workshop</a> for relevant discussions.</p>


        </article>

        <aside class="news-section">
          <h1>News & updates</h1>

          <div class="timeline">
            <!-- timeline content is dynamically generated by events.js -->
          </div>
        </aside>

        <article class="publications-section">

          <h1>Selected publications</h1>
            <br />

            <p><strong>Agentic AI Needs a Systems Theory</strong><br>
            E Miehling, KN Ramamurthy, KR Varshney, M Riemer, D Bouneffouf, JT Richards, A Dhurandhar, EM Daly, M Hind, P Sattigeri, D Wei, A Rawat, J Gajcin, W Geyer<br>
            <small>Preprint 2025 | <a href="https://arxiv.org/abs/2503.00237">paper</a></small></p>

            <p><strong>Evaluating the Prompt Steerability of Large Language Models</strong><br>
            E Miehling, M Desmond, KN Ramamurthy, EM Daly, KR Varshney, E Farchi, P Dognin, J Rios, D Bouneffouf, M Liu, P Sattigeri<br>
            <small>NAACL 2025 | <a href="https://arxiv.org/abs/2411.12405">paper</a> | <a href="https://github.com/IBM/prompt-steering">code</a></small></p>

            <p><strong>Programming Refusal with Conditional Activation Steering</strong><br>
            BW Lee, I Padhi, KN Ramamurthy, E Miehling, P Dognin, M Nagireddy, A Dhurandhar<br>
            <small>ICLR 2025 Spotlight | <a href="https://arxiv.org/abs/2409.05907">paper</a> | <a href="https://github.com/IBM/activation-steering">code</a></small></p>

            <p><strong>Language Models in Dialogue: Conversational Maxims for Human-AI Interactions</strong><br>
            E Miehling, M Nagireddy, P Sattigeri, EM Daly, D Piorkowski, JT Richards<br>
            <small>EMNLP 2024 Findings | <a href="https://arxiv.org/abs/2403.15115">paper</a></small></p>

            <p><strong>Information State Embedding in Partially Observable Cooperative Multi-Agent Reinforcement Learning</strong><br>
            W Mao, K Zhang, E Miehling, T Başar<br>
            <small>IEEE CDC 2020 | <a href="https://arxiv.org/abs/2004.01098">paper</a></small></p>

            <p><strong>Non-Cooperative Inverse Reinforcement Learning</strong><br>
            X Zhang, K Zhang, E Miehling, T Başar<br>
            <small>NeurIPS 2019 | <a href="https://arxiv.org/abs/1911.04220">paper</a></small></p>

            <br/>
            <br/>
            <br/>
            <br/>
            <br/>
            <br/>
            <br/>
            <br/>

        </article>
      </div>

    </div>

    <!-- Page footer for narrow screens (must be outside wrapper) -->
    <footer class="page-footer">
      <div class="theme-toggle-wrapper">
        <span class="theme-toggle-icon sun"><i class="fa-solid fa-sun"></i></span>
        <button class="theme-toggle" aria-label="Toggle dark mode" aria-checked="false" role="switch"></button>
        <span class="theme-toggle-icon moon"><i class="fa-solid fa-moon"></i></span>
      </div>
      <p><small>Theme forked from <a href="https://github.com/orderedlist">orderedlist</a></small></p>
    </footer>
    
    <script src="assets/events.js"></script>
    <script src="assets/theme.js"></script>
  </body>
</html>
